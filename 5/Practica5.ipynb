{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d9f5d25",
   "metadata": {},
   "source": [
    "## Práctica 5: Detección de Características\n",
    "\n",
    "### Ejercicio 1: Desarrolle una aplicación que permita:  \n",
    "\n",
    "a) A través de la interfaz modificar los parámetros del detector de características SIFT.  \n",
    "b) Seleccionar un área de interés en una imagen de elección una imagen de naturaleza médica y\n",
    "una imagen telemétrica.  \n",
    "c) Buscar esa área de interés (recuádrela en rojo) dentro de diferentes versiones de la imagen de\n",
    "partida (con cambios de traslación, escala y rotación) [NOTA: Estos cambios se pueden acometer\n",
    "con un editor de imágenes o con el trabajo hecho en prácticas previas]. Altere mediante la interfaz\n",
    "las configuraciones de parámetros para mejorar la detección.  \n",
    "d) Pruebe a hacer lo mismo que en el apartado c) con diferentes grados de deformación de la\n",
    "imagen. [NOTA: Estos cambios se pueden acometer con un editor de imágenes o con el trabajo\n",
    "hecho en prácticas previas].  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f6e9b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import filedialog\n",
    "import cv2\n",
    "from Transformaciones import Transformaciones\n",
    "import numpy as np\n",
    "\n",
    "# Función vacía usada como callback por los trackbars (no necesita hacer nada)\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "def select_roi(img):\n",
    "    \"\"\"\n",
    "    Permite al usuario seleccionar manualmente un área de interés (ROI)\n",
    "    sobre la imagen original. La ROI será usada posteriormente para\n",
    "    buscarla en versiones transformadas de la imagen.\n",
    "    \"\"\"\n",
    "    global roi_cords, roi_img\n",
    "    \n",
    "    print(\"Selecionar el Area de Interes (Pulse ENTER para continuar)\")\n",
    "    \n",
    "    # Muestra una ventana interactiva donde el usuario dibuja la ROI con el ratón\n",
    "    roi_temp = cv2.selectROI(\"Selecionar ROI\", img, False, False)\n",
    "    cv2.destroyWindow(\"Selecionar ROI\")\n",
    "    \n",
    "    # Si la ROI tiene ancho y alto válidos\n",
    "    if roi_temp[2] > 0 and roi_temp[3] > 0:\n",
    "        roi_cords = roi_temp\n",
    "        x, y, w, h = roi_cords\n",
    "        \n",
    "        # Recorta la imagen con las coordenadas seleccionadas\n",
    "        roi_img = img[y:y+h, x:x+w]\n",
    "        print(f\"ROI: = x={x}, y={y}, w={w}, h={h}\")\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "\n",
    "def configurate_SIFT(img):\n",
    "    \"\"\"\n",
    "    Crea una interfaz para ajustar los parámetros del detector SIFT.\n",
    "    Cada slider modifica un parámetro, y la imagen se actualiza en tiempo real.\n",
    "    Esto NO hace matching, solo sirve para visualizar los keypoints y elegir\n",
    "    buenos parámetros para SIFT.\n",
    "    \"\"\"\n",
    "    cv2.namedWindow('SIFT configuration')\n",
    "    \n",
    "    # Trackbars para ajustar cada parámetro de SIFT\n",
    "    cv2.createTrackbar('nfeatures', 'SIFT configuration', 500, 2000, nothing)\n",
    "    cv2.createTrackbar('nOctaveLayers', 'SIFT configuration', 3, 5, nothing)\n",
    "    cv2.createTrackbar('contrastThr.', 'SIFT configuration', 40, 100, nothing)\n",
    "    cv2.createTrackbar('edgeThreshold', 'SIFT configuration', 10, 20, nothing)\n",
    "    cv2.createTrackbar('sigma', 'SIFT configuration', 16, 30, nothing)\n",
    "    \n",
    "    print(\"Ajustar los parametros del SIFT. Presionar q para continuar\")\n",
    "    \n",
    "    while True:\n",
    "        # Lectura en tiempo real del valor de cada slider\n",
    "        params_SIFT['nfeatures'] = nfeat = cv2.getTrackbarPos('nfeatures', 'SIFT configuration')\n",
    "        params_SIFT['nOctaveLayers'] = nOc = cv2.getTrackbarPos('nOctaveLayers', 'SIFT configuration')\n",
    "        params_SIFT['contrastThr.'] = conTh = cv2.getTrackbarPos('contrastThr.', 'SIFT configuration') / 1000.0\n",
    "        params_SIFT['edgeThreshold'] = edge = cv2.getTrackbarPos('edgeThreshold', 'SIFT configuration')\n",
    "        params_SIFT['sigma'] = sigma = cv2.getTrackbarPos('sigma', 'SIFT configuration') / 10.0\n",
    "        \n",
    "        # Crear un detector SIFT con los parámetros ajustados\n",
    "        sift = cv2.SIFT_create(nfeat, nOc, conTh, edge, sigma)\n",
    "        \n",
    "        # Convertir a escala de grises para detectar keypoints\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Detectar keypoints y descriptores\n",
    "        keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "        \n",
    "        # Dibujar keypoints sobre la imagen\n",
    "        img_with_keypoints = cv2.drawKeypoints(\n",
    "            img, \n",
    "            keypoints, \n",
    "            None, \n",
    "            flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS\n",
    "        )\n",
    "        \n",
    "        cv2.imshow('SIFT configuration', img_with_keypoints)\n",
    "        \n",
    "        # Si el usuario pulsa 'q', termina la configuración\n",
    "        key = cv2.waitKey(100) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cv2.destroyWindow('SIFT configuration')\n",
    "    print(\"Parametros de SIFT configurados\")\n",
    "\n",
    "\n",
    "def detect_matches(img_trf, img_roi, num_matches = 10):\n",
    "    \"\"\"\n",
    "    Función principal del ejercicio:\n",
    "    - Detecta características SIFT en la ROI y en la imagen transformada.\n",
    "    - Realiza matching con FLANN.\n",
    "    - Filtra los mejores matches según la regla de Lowe.\n",
    "    - Calcula la homografía para localizar la ROI en la imagen transformada.\n",
    "    - Dibuja un rectángulo rojo indicando dónde aparece la ROI.\n",
    "    - Devuelve la imagen de resultados y la de matches.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Comprobación de seguridad\n",
    "    if img_trf is None or img_roi is None:\n",
    "        print(\"Error: Falta de ROI o imagen transformada\")\n",
    "        return None\n",
    "    \n",
    "    # Crear SIFT con los parámetros ajustados previamente\n",
    "    sift = cv2.SIFT_create(\n",
    "        nfeatures=params_SIFT['nfeatures'],\n",
    "        nOctaveLayers=params_SIFT['nOctaveLayers'],\n",
    "        contrastThreshold=params_SIFT['contrastThreshold'],\n",
    "        edgeThreshold=params_SIFT['edgeThreshold'],\n",
    "        sigma=params_SIFT['sigma']\n",
    "    )\n",
    "    \n",
    "    # Convertir imágenes a escala de grises\n",
    "    roi_gray = cv2.cvtColor(img_roi, cv2.COLOR_BGR2GRAY)\n",
    "    trf_gray = cv2.cvtColor(img_trf, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detectar keypoints y descriptores en ROI y transformada\n",
    "    kp_roi, des_roi = sift.detectAndCompute(roi_gray, None)\n",
    "    kp_trf, des_trf = sift.detectAndCompute(trf_gray, None)\n",
    "    \n",
    "    print(f\"Roi Keypoints: {len(kp_roi)}, Transformada Keypoints: {len(kp_trf)}\")\n",
    "    \n",
    "    # Si hay pocos descriptores la homografía no es fiable\n",
    "    if des_roi is None or des_trf is None or len(kp_roi) < 2 or len(kp_trf) < 2:\n",
    "        print(\"Pocas caracteristicas encontradas\")\n",
    "        return None\n",
    "    \n",
    "    # FLANN para hacer matching rápido en espacios de alta dimensión\n",
    "    flann = cv2.FlannBasedMatcher(\n",
    "        dict(algorithm=1, trees=5), \n",
    "        dict(checks=50)\n",
    "    )\n",
    "    \n",
    "    # Encontrar los dos mejores matches para cada descriptor de la ROI\n",
    "    matches = flann.knnMatch(des_roi, des_trf, k=2)\n",
    "    \n",
    "    # Regla de Lowe: solo se considera bueno si el match es claramente mejor que el segundo\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.75 * n.distance:\n",
    "            good_matches.append(m)\n",
    "        \n",
    "    print(f\"Matches buenos: {len(good_matches)}\")\n",
    "    \n",
    "    # Si no hay suficientes matches, no se puede calcular homografía\n",
    "    if len(good_matches) < num_matches:\n",
    "        print(f\"Pocos matches ({len(good_matches)} < {num_matches})\")\n",
    "        return None\n",
    "    \n",
    "    # Extraer las coordenadas de los puntos coincidentes\n",
    "    src_pts = np.float32([kp_roi[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kp_trf[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    \n",
    "    # Calcular homografía con RANSAC (permite tolerar outliers)\n",
    "    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "    \n",
    "    if M is None:\n",
    "        print(\"No se pudo calcular la homografía\")\n",
    "        return None\n",
    "    \n",
    "    # Crear un rectángulo rojo alrededor de la posición estimada de la ROI\n",
    "    h, w = roi_gray.shape\n",
    "    pts = np.float32([[0, 0], [0, h-1], [w-1, h-1], [w-1, 0]]).reshape(-1, 1, 2)\n",
    "    \n",
    "    # Transformar los puntos según la homografía calculada\n",
    "    dst = cv2.perspectiveTransform(pts, M)\n",
    "    \n",
    "    img_result = img_trf.copy()\n",
    "    img_result = cv2.polylines(img_result, [np.int32(dst)], True, (0, 0, 255), 3)\n",
    "    \n",
    "    # Dibuja los matches entre ROI e imagen transformada\n",
    "    img_matches = cv2.drawMatches(\n",
    "        img_roi, kp_roi,\n",
    "        img_trf, kp_trf,\n",
    "        good_matches[:50],\n",
    "        None,\n",
    "        flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",
    "    )\n",
    "    \n",
    "    print(\"Roi Encontrado\")\n",
    "    return img_result, img_matches, M, len(good_matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa7dde80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecionar el Area de Interes (Pulse ENTER para continuar)\n",
      "Select a ROI and then press SPACE or ENTER button!\n",
      "Cancel the selection process by pressing c button!\n",
      "ROI: = x=373, y=94, w=32, h=45\n",
      "Ajustar los parametros del SIFT. Presionar q para continuar\n",
      "Parametros de SIFT configurados\n",
      "Roi Keypoints: 45, Transformada Keypoints: 1562\n",
      "Matches buenos: 5\n",
      "Roi Encontrado\n"
     ]
    }
   ],
   "source": [
    "# CARGA DE LA IMAGEN ORIGINAL\n",
    "\n",
    "# Abre una ventana para seleccionar la imagen desde el explorador\n",
    "ruta = filedialog.askopenfilename(title=\"Selecciona una imagen\")\n",
    "\n",
    "# Carga la imagen seleccionada en memoria\n",
    "img_original = cv2.imread(ruta)\n",
    "\n",
    "# Verificación por si la imagen no se ha podido cargar correctamente\n",
    "if img_original is None:\n",
    "    print(\"Error: no se pudo cargar la imagen\")\n",
    "    exit()\n",
    "\n",
    "# Reducción de tamaño para facilitar el procesamiento (20% del tamaño original)\n",
    "img_original = cv2.resize(img_original, None, fx=0.2, fy=0.2)\n",
    "\n",
    "# Variables globales donde se guardará la ROI seleccionada\n",
    "roi_cords = None\n",
    "roi_img = None\n",
    "\n",
    "# SELECCIÓN DE LA ROI (REGIÓN DE INTERÉS)\n",
    "\n",
    "# El usuario selecciona manualmente el área que quiere buscar\n",
    "select_roi(img_original)\n",
    "\n",
    "# Variable para almacenar la imagen transformada\n",
    "img_transformada = None\n",
    "\n",
    "# CREACIÓN DE LA CLASE DE -TRANSFORMACIONES-\n",
    "\n",
    "transformaciones = Transformaciones(img_original)\n",
    "\n",
    "transformaciones.distorcion()\n",
    "img_transformada = transformaciones.distorcioned\n",
    "\n",
    "#transformaciones.transformacion()\n",
    "#img_transformada = transformaciones.transformed\n",
    "\n",
    "\n",
    "# PARÁMETROS INICIALES DEL DETECTOR SIFT\n",
    "\n",
    "params_SIFT = {\n",
    "    \"nfeatures\": 500,          # Número máximo de keypoints a detectar\n",
    "    \"nOctaveLayers\": 3,        # Número de capas por octava\n",
    "    \"contrastThreshold\": 0.04, # Umbral de contraste para eliminar puntos débiles\n",
    "    \"edgeThreshold\": 10,       # Umbral para descartar bordes inestables\n",
    "    \"sigma\": 1.6               # Suavizado aplicado en la primera octava\n",
    "}\n",
    "\n",
    "# AJUSTE INTERACTIVO DE SIFT POR EL USUARIO\n",
    "\n",
    "# Se abre una ventana con sliders para modificar los parámetros de SIFT\n",
    "# Mientras se mueven, se muestran los keypoints actualizados en tiempo real.\n",
    "configurate_SIFT(img_original)\n",
    "\n",
    "\n",
    "# DETECCIÓN DE LA ROI EN LA IMAGEN TRANSFORMADA\n",
    "\n",
    "resultado = detect_matches(img_transformada, roi_img, 5)\n",
    "\n",
    "# Si no hay resultados suficientes, se informa por pantalla\n",
    "if resultado is None:\n",
    "    print(\"No se encontraron matches suficientes\")\n",
    "\n",
    "else:\n",
    "    # Si se encuentra la ROI, se obtienen imágenes de resultados:\n",
    "    # - imgen_result : imagen transformada con cuadro rojo alrededor de la ROI encontrada\n",
    "    # - imgen_matches : visualización de matches entre ROI y transformada\n",
    "    # - M : homografía calculada\n",
    "    # - tam : número de matches buenos\n",
    "    imgen_result, imgen_matches, M, tam = resultado\n",
    "\n",
    "    \n",
    "    # VISUALIZACIÓN FINAL DE RESULTADOS\n",
    "\n",
    "    while True:\n",
    "        # Imagen original sin transformar (solo para referencia visual)\n",
    "        cv2.imshow(\"Imagen Original\", img_original)\n",
    "\n",
    "        # Imagen mostrando los matches entre ROI y transformada\n",
    "        cv2.imshow(\"Imagen Matches\", imgen_matches)\n",
    "\n",
    "        # Imagen transformada con el rectángulo rojo indicando la coincidencia\n",
    "        cv2.imshow(\"Imagen Resultados\", imgen_result)\n",
    "\n",
    "        # Espera de teclado — si el usuario pulsa ESC (27), se cierra\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == 27:\n",
    "            break\n",
    "\n",
    "    # Cierra todas las ventanas abiertas por OpenCV\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e8fb15",
   "metadata": {},
   "source": [
    "### Significado de los parámetros SIFT\n",
    " - nfeatures\n",
    "\n",
    "Cuántos puntos máximos intenta detectar.\n",
    "\n",
    "Alto → detecta más detalles (aunque sean débiles).\n",
    "\n",
    "Bajo → solo los puntos más fuertes.\n",
    "\n",
    "- contrastThreshold\n",
    "\n",
    "Controla cuánto contraste debe tener un punto para ser considerado importante.\n",
    "\n",
    "Bajo → detecta puntos más débiles (más “ruido” pero más matches).\n",
    "\n",
    "Alto → menos puntos, pero más fiables.\n",
    "\n",
    "- edgeThreshold\n",
    "\n",
    "Controla si descarta puntos que solo están en bordes “planos” o alargados.\n",
    "\n",
    "Bajo → detecta casi todo.\n",
    "\n",
    "Alto → descarta muchos puntos en bordes simples (muy útil en ropa, logotipos planos, etc.).\n",
    "\n",
    "- sigma\n",
    "\n",
    "Suavizado inicial.\n",
    "\n",
    "Bajo → detecta detalles pequeños.\n",
    "\n",
    "Alto → detecta estructuras grandes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
